# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/08_anomaly.heuristics.ipynb.

# %% auto 0
__all__ = ['f_score', 'load_pred_model', 'multivariate_anomaly_score', 'get_score_df', 'get_preds', 'get_th_df',
           'get_best_threshhold', 'get_fixed_heuristic', 'get_ratio_th', 'elbow_heuristic',
           'get_lowest_plateau_heuristic']

# %% ../../nbs/08_anomaly.heuristics.ipynb 4
from fastai.basics import *
from ..process import *
from .detect import *
from sklearn.metrics import confusion_matrix
from fastai.tabular.model import get_emb_sz
from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
import seaborn as sns

# %% ../../nbs/08_anomaly.heuristics.ipynb 6
# Custom F_Score of PDC Challenge:
def f_score(y_true, y_pred,sample_weight=None):
    C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)
    with np.errstate(divide="ignore", invalid="ignore"):
        per_class = np.diag(C) / C.sum(axis=1)
    if np.any(np.isnan(per_class)):
        warnings.warn("y_pred contains classes not in y_true")
        per_class = per_class[~np.isnan(per_class)]
    P = per_class[0]
    N = per_class[1]
    score = 2*(P*N)/(P+N)
    return score

# %% ../../nbs/08_anomaly.heuristics.ipynb 7
def load_pred_model(learner_path,train_log_path,log_name,cols=['activity']):
    p = f'{learner_path}/{log_name}_vocab.p'
    with open(p, 'rb') as fp:
        categorify = pickle.load(fp)
    log = import_log(train_log_path)
    o = process_test(log,categorify,cols)
    dls=o.get_dls()
    loss=partial(multi_loss_sum,o)
    emb_szs = get_emb_sz(o)
    m=MultivariateModel(emb_szs)
    learn=Learner(dls, m, path=learner_path, model_dir='.', loss_func=loss, metrics=get_metrics(o))
    learn.load(log_name,with_opt=False)
    m=learn.model.cuda()
    return m, categorify

# %% ../../nbs/08_anomaly.heuristics.ipynb 8
def multivariate_anomaly_score(res,o,idx,cols,normalization = True):
    score_df=pd.DataFrame()

    for cidx,_ in enumerate(cols):
        sm = nn.Softmax(dim=1)
        p = sm(res[cidx].cpu())
        pred = p.max(1)[0]
        y = o.items[cols[cidx]].iloc[idx].values

        truth=p[list(range(len(y))),y]
        if normalization:
            score = ((pred - truth) / pred).tolist()
        else:
            score = (pred - truth).tolist()
        score_df[cols[cidx]] = score
    score_df['trace_id']=o.items.index.to_series().iloc[idx].values
    return score_df

# %% ../../nbs/08_anomaly.heuristics.ipynb 9
def get_score_df(log_name,prediction_normalization = True):
    learner_path=f'../models/pdc2020'
    training_log_path = f'../data/logs/csv/dapnn_ds/PDC2020_training/pdc_2020_{log_name}.csv.gz'
    test_log_path = f'../data/logs/csv/dapnn_ds/PDC2020_ground_truth/pdc_2020_{log_name}.csv.gz' 
    
    cols = ['activity']
    m, categorify= load_pred_model(learner_path,training_log_path,f"pdc_2020_{log_name}")
    if type(test_log_path)==str:
        log = import_log_pdc(test_log_path)
    else:
        log = test_log_path   
    o = process_test(log,categorify,cols)
    nsp,idx=predict_next_step(o,m)
    score_df=multivariate_anomaly_score(nsp,o,idx,cols,prediction_normalization)
    y_true =o.items['normal'].astype(float).groupby(o.items.index).mean().to_numpy() ==False
    return score_df, y_true

# %% ../../nbs/08_anomaly.heuristics.ipynb 12
def get_preds(score_df,threshold):
    h =score_df.groupby('trace_id')['activity'].max()
    h=(h-h.min())/(h.max()-h.min())

    y_pred = (h.to_numpy()>threshold).astype(int)
    return y_pred


# %% ../../nbs/08_anomaly.heuristics.ipynb 14
def get_th_df(ths,score_df,y_true,log_name,f_score=f_score):
    res = []
    for t in progress_bar(ths):
        y_pred=get_preds(score_df,t)
        anomaly_ratio = sum(x == 1 for x in y_pred) / len(y_pred)
        f1 = f_score(y_true, y_pred)
        precision = precision_score(y_true,y_pred)
        recall = recall_score(y_true,y_pred)
        res.append([log_name, f1, precision, recall, anomaly_ratio])

    columns='Log Name', 'F1 Score','Precision','Recall', 'Anomaly Ratio'
    th_df = pd.DataFrame(res,columns=columns,index=ths)
    return th_df


# %% ../../nbs/08_anomaly.heuristics.ipynb 18
def get_best_threshhold(th_df): return th_df.iloc[th_df['F1 Score'].argmax()]


# %% ../../nbs/08_anomaly.heuristics.ipynb 21
def get_fixed_heuristic(fixed,th_df): return th_df.iloc[np.absolute(th_df.index.to_numpy()-fixed).argmin()]


# %% ../../nbs/08_anomaly.heuristics.ipynb 24
def get_ratio_th(ratio,th_df):return th_df.iloc[th_df['Anomaly Ratio'].sub(ratio).abs().argmin()]


# %% ../../nbs/08_anomaly.heuristics.ipynb 28
def elbow_heuristic(th_df):
    taus = th_df.index.to_numpy()
    r = th_df['Anomaly Ratio'].to_numpy()
    step = taus[1:] - taus[:-1]
    r_prime_prime = (r[2:] - 2 * r[1:-1] + r[:-2]) / (step[1:] * step[:-1])
    ellbow_down = th_df.iloc[np.argmax(r_prime_prime) + 1]
    ellbow_up = th_df.iloc[np.argmin(r_prime_prime) + 1]
    return ellbow_down,ellbow_up


# %% ../../nbs/08_anomaly.heuristics.ipynb 31
def get_lowest_plateau_heuristic(th_df):
    taus = th_df.index.to_numpy()
    r = th_df['Anomaly Ratio'].to_numpy()
    r_prime = (r[1:] - r[:-1]) / (taus[1:] - taus[:-1])
    stable_region = r_prime > np.mean(r_prime) / 2
    regions = np.split(np.arange(len(stable_region)), np.where(~stable_region)[0])
    regions = [taus[idx[1:]] for idx in regions if len(idx) > 1]
    if len(regions) == 0:
        regions = [taus[-2:]]
    lp_min = get_fixed_heuristic(regions[-1].min(),th_df)
    lp_mean = get_fixed_heuristic(regions[-1].mean(),th_df)
    lp_max = get_fixed_heuristic(regions[-1].max(),th_df)
    return lp_min,lp_mean,lp_max

