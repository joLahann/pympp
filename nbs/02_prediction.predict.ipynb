{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prediction.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pympp.process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpi12 ='../data/logs/csv/mppn_ds/BPIC12.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>REG_DATE</th>\n",
       "      <th>AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>###start###</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "      <td>A_SUBMITTED_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:38:44.880000+00:00</td>\n",
       "      <td>A_PARTLYSUBMITTED_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:39:37.906000+00:00</td>\n",
       "      <td>A_PREACCEPTED_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "      <td>W_Completeren aanvraag_SCHEDULE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214376</th>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2012-02-29 22:52:01.287000+00:00</td>\n",
       "      <td>W_Afhandelen leads_SCHEDULE</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214376</th>\n",
       "      <td>4</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>2012-03-01 08:26:46.736000+00:00</td>\n",
       "      <td>W_Afhandelen leads_START</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214376</th>\n",
       "      <td>5</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>2012-03-01 08:27:37.118000+00:00</td>\n",
       "      <td>A_DECLINED_COMPLETE</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214376</th>\n",
       "      <td>6</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>2012-03-01 08:27:41.325000+00:00</td>\n",
       "      <td>W_Afhandelen leads_COMPLETE</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214376</th>\n",
       "      <td>7</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>2012-03-01 08:27:41.325000+00:00</td>\n",
       "      <td>###end###</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288374 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         event_id resource                         timestamp  \\\n",
       "trace_id                                                       \n",
       "173688          0    112.0  2011-09-30 22:38:44.546000+00:00   \n",
       "173688          1    112.0  2011-09-30 22:38:44.546000+00:00   \n",
       "173688          2    112.0  2011-09-30 22:38:44.880000+00:00   \n",
       "173688          3    112.0  2011-09-30 22:39:37.906000+00:00   \n",
       "173688          4    112.0  2011-09-30 22:39:38.875000+00:00   \n",
       "...           ...      ...                               ...   \n",
       "214376          3    112.0  2012-02-29 22:52:01.287000+00:00   \n",
       "214376          4  11169.0  2012-03-01 08:26:46.736000+00:00   \n",
       "214376          5  11169.0  2012-03-01 08:27:37.118000+00:00   \n",
       "214376          6  11169.0  2012-03-01 08:27:41.325000+00:00   \n",
       "214376          7  11169.0  2012-03-01 08:27:41.325000+00:00   \n",
       "\n",
       "                                 activity                          REG_DATE  \\\n",
       "trace_id                                                                      \n",
       "173688                        ###start###  2011-10-01 00:38:44.546000+02:00   \n",
       "173688               A_SUBMITTED_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688         A_PARTLYSUBMITTED_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688             A_PREACCEPTED_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688    W_Completeren aanvraag_SCHEDULE  2011-10-01 00:38:44.546000+02:00   \n",
       "...                                   ...                               ...   \n",
       "214376        W_Afhandelen leads_SCHEDULE  2012-02-29 23:51:16.799000+01:00   \n",
       "214376           W_Afhandelen leads_START  2012-02-29 23:51:16.799000+01:00   \n",
       "214376                A_DECLINED_COMPLETE  2012-02-29 23:51:16.799000+01:00   \n",
       "214376        W_Afhandelen leads_COMPLETE  2012-02-29 23:51:16.799000+01:00   \n",
       "214376                          ###end###  2012-02-29 23:51:16.799000+01:00   \n",
       "\n",
       "         AMOUNT_REQ  \n",
       "trace_id             \n",
       "173688        20000  \n",
       "173688        20000  \n",
       "173688        20000  \n",
       "173688        20000  \n",
       "173688        20000  \n",
       "...             ...  \n",
       "214376        15000  \n",
       "214376        15000  \n",
       "214376        15000  \n",
       "214376        15000  \n",
       "214376        15000  \n",
       "\n",
       "[288374 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(bpi12)\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 12616 #events: 249149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193068</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193068</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193068</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col='activity'\n",
    "o=PPObj(log,procs=Categorify(),cat_names=col,y_names=col,splits=split_traces(log))\n",
    "o.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 5]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls=o.get_dls()\n",
    "xb,yb=dls.one_batch()\n",
    "xb.shape,yb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/logs/csv/mppn_ds/Helpdesk.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>resource</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case1</th>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-09 11:50:17+00:00</td>\n",
       "      <td>###start###</td>\n",
       "      <td>Value 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-09 11:50:17+00:00</td>\n",
       "      <td>Assign seriousness</td>\n",
       "      <td>Value 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-09 11:51:01+00:00</td>\n",
       "      <td>Take in charge ticket</td>\n",
       "      <td>Value 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case1</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-10-12 12:02:56+00:00</td>\n",
       "      <td>Take in charge ticket</td>\n",
       "      <td>Value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case1</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-25 08:54:26+00:00</td>\n",
       "      <td>Resolve ticket</td>\n",
       "      <td>Value 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         event_id                  timestamp               activity resource\n",
       "trace_id                                                                    \n",
       "Case1           0  2012-10-09 11:50:17+00:00            ###start###  Value 1\n",
       "Case1           1  2012-10-09 11:50:17+00:00     Assign seriousness  Value 1\n",
       "Case1           2  2012-10-09 11:51:01+00:00  Take in charge ticket  Value 1\n",
       "Case1           3  2012-10-12 12:02:56+00:00  Take in charge ticket  Value 2\n",
       "Case1           4  2012-10-25 08:54:26+00:00         Resolve ticket  Value 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(path)\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 30508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case3756</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case3756</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case3756</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col='activity'\n",
    "o=PPObj(log,procs=Categorify(),cat_names=col,y_names=col,splits=split_traces(log))\n",
    "o.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 5]),\n",
       " torch.Size([64]),\n",
       " tensor([[ 0,  2,  3, 14, 16]], device='cuda:0'),\n",
       " 17)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls=o.get_dls()\n",
    "xb,yb=dls.one_batch()\n",
    "xb.shape,yb[0].shape,xb[0], len(o.procs.categorify[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from math import sqrt\n",
    "from fastai.torch_basics import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.callback.all import *\n",
    "from fastai.learner import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RNNwEmbedding(torch.nn.Module) :\n",
    "    def __init__(self,o) :\n",
    "        super().__init__()\n",
    "        vocab_size=len(o.procs.categorify[o.y_names[0]])\n",
    "        emb_size = int(sqrt(vocab_size))+1\n",
    "        hidden_six = 20\n",
    "        self.emb = nn.Embedding(vocab_size,emb_size)\n",
    "\n",
    "        self.rnn = nn.RNN(emb_size, hidden_six, batch_first=True, num_layers=2)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_six, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x.squeeze())\n",
    "        x,_ = self.rnn(x)\n",
    "        x = x[:,-1]\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=RNNwEmbedding(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cross_entropy_targ0(inp, targ):\n",
    "    return F.cross_entropy(inp,targ[0])\n",
    "\n",
    "def accuracy_targ0(inp, targ, axis=-1):\n",
    "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
    "    pred,targ = flatten_check(inp.argmax(dim=axis), targ[0])\n",
    "    return (pred == targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HideOutput:\n",
    "    'A utility function that hides all outputs in a context'\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=m(xb.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def training_loop(learn,epoch,print_output,lr_find):\n",
    "    '''\n",
    "    Basic training loop that uses learning rate finder and one cycle training. \n",
    "    See fastai docs for more information\n",
    "    '''\n",
    "    if lr_find:\n",
    "        lr=np.median([learn.lr_find(show_plot=print_output)[0] for i in range(5)])\n",
    "        learn.fit_one_cycle(epoch,float(lr))\n",
    "    else: learn.fit(epoch,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_validate(dls,m,metrics=accuracy,loss=F.cross_entropy,epoch=20,print_output=True,model_dir=\".\",lr_find=True,\n",
    "                   output_index=1,patience=3,min_delta=0.005,show_plot=True,store_path='tmp',model_name='.model'):\n",
    "    '''\n",
    "    Trains a model on the training set with early stopping based on the validation loss.\n",
    "    Afterwards, applies it to the test set.\n",
    "    '''\n",
    "    cbs = [\n",
    "      EarlyStoppingCallback(monitor='valid_loss',min_delta=min_delta, patience=patience),\n",
    "      SaveModelCallback(fname=model_name)\n",
    "      ]\n",
    "    learn=Learner(dls, m, path=store_path, model_dir=model_dir, loss_func=loss ,metrics=metrics,cbs=cbs)\n",
    "\n",
    "    if print_output:\n",
    "        training_loop(learn,epoch,show_plot,lr_find=lr_find)\n",
    "        return learn.validate(dl=dls[2])[output_index]\n",
    "    else:\n",
    "        with HideOutput(),learn.no_bar(),learn.no_logging():\n",
    "            training_loop(learn,epoch,show_plot,lr_find=lr_find)\n",
    "            return learn.validate(dl=dls[2])[output_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858601450920105"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols,outcome='activity',False\n",
    "o=PPObj(log,procs=Categorify(),cat_names=cols,y_names=cols,splits=split_traces(log))\n",
    "dls=o.get_dls(outcome=outcome,windows=partial(windows_fast))\n",
    "m=RNNwEmbedding(o)\n",
    "train_validate(dls,m,epoch=5,metrics=accuracy_targ0,loss=lambda x,y: F.cross_entropy(x,y[0]),print_output=False,show_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Prediction Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PPModel` class creates multiple prediction models for next-step prediction, next-resource prediction, remaining time prediction, etc. based on a pytorch model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Todo: Add Logging\n",
    "class PPModel():\n",
    "\n",
    "    def __init__(self,log,ds_name,splits,store=None,bs=64,print_output=False,patience=3,min_delta=0.005,\n",
    "                 attr_dict=None,windows=windows_fast,epoch=20,sample=False,\n",
    "                 train_validate=train_validate):\n",
    "        store_attr('log,ds_name,splits,attr_dict,windows,epoch,bs,print_output,min_delta,patience,store')\n",
    "        self.lr_find=True\n",
    "        if sample:\n",
    "            self.lr_find=False\n",
    "            traces=self.splits[0]\n",
    "            self.splits=traces[:60],traces[60:80],traces[80:100]\n",
    "            self.bs=64\n",
    "            self.epoch=1\n",
    "\n",
    "    def evaluate(self):\n",
    "        if not self.print_output:\n",
    "            with HideOutput(): return self.__evaluate()\n",
    "        else: return self.__evaluate()\n",
    "    def __evaluate(self):\n",
    "        print(self.ds_name,self.get_name())\n",
    "        self.setup()\n",
    "\n",
    "        print('next_step_prediction')\n",
    "        nsp=self.next_step_prediction()\n",
    "\n",
    "        print('next_resource_prediction')\n",
    "        nrp=self.next_resource_prediction()\n",
    "\n",
    "        print('last_resource_prediction')\n",
    "        lrp=self.last_resource_prediction()\n",
    "\n",
    "        print('outcome_prediction')\n",
    "        op=self.outcome_prediction()\n",
    "\n",
    "        print('duration_to_next_event_prediction')\n",
    "        dtnep=self.duration_to_next_event_prediction()\n",
    "\n",
    "        print('duration_to_end_prediction')\n",
    "        dtep=self.duration_to_end_prediction()\n",
    "\n",
    "        print('activity_suffix_prediction')\n",
    "        asp=self.activity_suffix_prediction()\n",
    "\n",
    "        print('resource_suffix_prediction')\n",
    "        rsp=self.resource_suffix_prediction()\n",
    "\n",
    "        return nsp, nrp, lrp, op, dtnep, dtep, asp, rsp\n",
    "\n",
    "    def _train_validate(self,dls,m,metrics=accuracy,loss=F.cross_entropy,output_index=1):\n",
    "        store,model_name='tmp','.model'\n",
    "        if self.store:\n",
    "            ins_stack=inspect.stack()\n",
    "            model_name=str(ins_stack[2][3]) if str(ins_stack[2][3])!='__evaluate' else str(ins_stack[1][3])\n",
    "            store=self.store/self.ds_name/self.get_name()\n",
    "        return train_validate(dls,m,metrics=metrics,loss=loss,output_index=output_index, #Only change these\n",
    "                              epoch=self.epoch,print_output=self.print_output,patience=self.patience,\n",
    "                              min_delta=self.min_delta,show_plot=False,store_path=store,model_name=model_name,\n",
    "                              lr_find=self.lr_find)\n",
    "    def setup(self): pass\n",
    "    def get_name(self): return self.__class__.__name__.replace('PPM_',\"\")\n",
    "    def next_step_prediction(self): pass\n",
    "    def next_resource_prediction(self): pass\n",
    "    def last_resource_prediction(self): pass\n",
    "    def outcome_prediction(self): pass\n",
    "    def duration_to_next_event_prediction(self): pass\n",
    "    def duration_to_end_prediction(self): pass\n",
    "    def activity_suffix_prediction(self): pass\n",
    "    def resource_suffix_prediction(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_ds_name(url): return(Path(url).stem) # Utility function, that gets the name of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PPM_RNNwEmbedding(PPModel):\n",
    "    'Sampe PPM based on RNNwEmbedding'\n",
    "    model=RNNwEmbedding\n",
    "\n",
    "    def next_step_prediction(self,outcome=False,col='activity'):\n",
    "        o=PPObj(self.log,procs=Categorify(),cat_names=col,y_names=col,splits=self.splits)\n",
    "        dls=o.get_dls(outcome=outcome,bs=self.bs,windows=self.windows)\n",
    "        m=self.model(o)\n",
    "        return self._train_validate(dls,m,metrics=accuracy_targ0,loss=cross_entropy_targ0)\n",
    "\n",
    "    def next_resource_prediction(self): return self.next_step_prediction(col='resource')\n",
    "    def last_resource_prediction(self): return self.next_step_prediction(col='resource',outcome=True)\n",
    "    def outcome_prediction(self): return self.next_step_prediction(outcome=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=import_log(path)\n",
    "ds_name=get_ds_name(path)\n",
    "splits=split_traces(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm=PPM_RNNwEmbedding(log,ds_name,splits,epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853634774684906"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppm.next_step_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A runner function for `PPModel`. Runs multiple prediction models on various datasets for several runs. Writes the results to a dataframe and stores it on disk in the `./tmp` folder. Stores the splits, the trained models, and the results. Accepts multiple parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "import inspect\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Performance_Statistic():\n",
    "    'Creates a results dataframe, that shows the performance of all models on all datasets on all tasks.'\n",
    "    def __init__(self):\n",
    "        self.df = pd.DataFrame(\n",
    "        columns=['Dataset', 'Model', 'Next Step', 'Next Resource', 'Last Resource', 'Outcome',\n",
    "                'Next relative Timestamp', 'Duration to Outcome', 'Activity Suffix', 'Resource Suffix'])\n",
    "    def update(self,model_performance): self.df.loc[len(self.df)] = model_performance\n",
    "    def to_df(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _store_path(results_dir=Path('./tmp')):\n",
    "    'Creates a new folder to store results'\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    results_dir=results_dir/current_time\n",
    "    results_dir.mkdir()\n",
    "    return results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(PPModel)\n",
    "def runner(dataset_urls,ppm_classes,store=True,runs=1,sample=False,seed=42,tqdm=tqdm,\n",
    "           **kwargs):\n",
    "    store_path= _store_path() if store else None\n",
    "    '''\n",
    "    Runs a number of process prediction models PPModel on a number of datasets for multiple runs.\n",
    "    Stores results in ./tmp folder.\n",
    "    '''\n",
    "    i=0\n",
    "    results=[]\n",
    "    for r in tqdm(range(runs),desc='Runs'):\n",
    "        performance_statistic = Performance_Statistic()\n",
    "        db=tqdm(range(len(dataset_urls)),leave=False)\n",
    "        for i in db:\n",
    "            db.set_description(get_ds_name(dataset_urls[i]))\n",
    "            ds= dataset_urls[i]\n",
    "            log=import_log(ds)\n",
    "            ds_name=get_ds_name(ds)\n",
    "            splits=split_traces(log,ds_name,seed=seed)\n",
    "            if store:\n",
    "                with open(store_path/f'run{r}_{ds_name}_splits.pickle', \"wb\") as output_file:\n",
    "                    pickle.dump(splits, output_file)\n",
    "            mb=tqdm(range(len(ppm_classes)),leave=False)\n",
    "            for j in mb:\n",
    "                mb.set_description(ppm_classes[j].__name__.replace('PPM_',\"\"))\n",
    "                ppm_class=ppm_classes[j]\n",
    "                model_path=store_path/'models'/f\"run{r}\" if store else None\n",
    "                model=ppm_class(log,ds_name,splits,store=model_path,sample=sample,**kwargs)\n",
    "                model_performance = model.evaluate()\n",
    "                model_performance = [ds_name, model.get_name(),*model_performance]\n",
    "                performance_statistic.update(model_performance)\n",
    "                [ds_name, model.get_name(),*model_performance]\n",
    "\n",
    "        df = performance_statistic.to_df()\n",
    "        results.append(df)\n",
    "        if store: df.to_csv(store_path/f\"run_{r}_results.csv\")\n",
    "    return results if len(results)>1 else results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample shows how to use the runner function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285517fef5e94dba8c6a75e98cea1217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 23.1 s, total: 26 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset_paths=[path]\n",
    "ppms=[PPM_RNNwEmbedding,PPM_RNNwEmbedding]\n",
    "res=runner(dataset_paths,ppms,epoch=1,store=True,print_output=False,\n",
    "           sample=True,runs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Next Step</th>\n",
       "      <th>Next Resource</th>\n",
       "      <th>Last Resource</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Next relative Timestamp</th>\n",
       "      <th>Duration to Outcome</th>\n",
       "      <th>Activity Suffix</th>\n",
       "      <th>Resource Suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helpdesk</td>\n",
       "      <td>RNNwEmbedding</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helpdesk</td>\n",
       "      <td>RNNwEmbedding</td>\n",
       "      <td>0.635593</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Next Step</th>\n",
       "      <th>Next Resource</th>\n",
       "      <th>Last Resource</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Next relative Timestamp</th>\n",
       "      <th>Duration to Outcome</th>\n",
       "      <th>Activity Suffix</th>\n",
       "      <th>Resource Suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helpdesk</td>\n",
       "      <td>RNNwEmbedding</td>\n",
       "      <td>0.313559</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helpdesk</td>\n",
       "      <td>RNNwEmbedding</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.245763</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"RUN\",0)\n",
    "display_df(res[0])\n",
    "\n",
    "print (\"RUN\",1)\n",
    "display_df(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pympp",
   "language": "python",
   "name": "pympp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
